# Coordinate review

Partially distilled from AI summaries with:

* Gemini — 3
* Claude — Opus 4.5
* Cursor — auto

**Note** - items to check — search for `**Check**`.

## Background

Let us imagine a 2D grayscale image.

To be more concrete, let's load such an image:

```{python}
import numpy as np
import skimage as ski

import matplotlib.pyplot as plt

# Set default 2D image colormap.
plt.rc('image', cmap='gray')

img = ski.data.camera()
img.shape
```

Let us now imagine that we want to identify a pixel by its
coordinate.

A coordinate is a pair of numbers identifying the pixel.

For example, we may have a coordinate (5, 10).  To interpret
this coordinate, we need to know what the 5 and 10 refer to.
Put another way, we have to know what *coordinate axes* the
5 and 10 relate to.  The coordinate axes specify a *coordinate
system*.

There are two common coordinate systems in imaging.

## The array coordinate system

The first coordinate system will appear the most obvious to
experienced users of Numpy — is is the array coordinate
system, also know as the *matrix* or *linear algebra*
coordinate system.  We will also call this the "i, j" coordinate system, for reasons that should become clear.

This interprets the first number (here 5) as the *position* along the first axis of the array, and the second number (here 10) as a position along the second axis of the array.

In other words, the pixel at (5, 10), using the array coordinate system, is given by the Numpy operation:

```{python}
img[5, 10]
```

So, in this case, the coordinate system is given by the array
axes.

Here is the `cameraman` image displayed in Matplotlib.

```{python}
plt.imshow(img)
```

Notice that, in terms of the image we have just displayed, the
first axis is top to bottom, starting at 0, and the second
axis is left to right, starting at 0.

We call this the "ij" coordinate system on the basis that "i"
will always refer to the first array axis, and "j" to the
second.  We chose "i" and "j" to have no particular meaning in
terms of the way the image is displayed - to remind us that
this meaning is strictly in terms of the axes of the image
array.

## The imaging coordinate system

There is another common coordinate system in imaging, that we
will call the *imaging coordinate system*, or the "x, y"
coordinate system.

Very confusingly, the first axis in the imaging coordinate system corresponds to the *second* axis in the image array, and the second axis in the imaging coordinate system corresponds to the *first* axis in the image array.

Imagine I have some coordinate (11, 20).  If that is a coordinate in the imaging coordinate system, then the equivalent pixel in that coordinate system is given by:

```{python}
img[20, 11]
```

In terms of the display above, the first axis of the
coordinate system runs from left to right, starting at 0, and
the second axis in the coordinate system runs from top to
bottom, starting at 0.

Why is this *imaging* coordinate system popular?  Because it
matches, in part, the way we think of axes on a graph.  On
a graph, the first axis is *x* and runs from left to right,
and the second is *y* and it runs from bottom to top.  With
images, we often think of the first values in the image as
being at the *top* of the image (not the bottom), so, for the
imaging coordinate convention, it's most common to think of
the y (second) axis as running top to bottom (rather than the
y-axis of standard graphs, which run from bottom to top).

Notice that the labels "x" and "y" refer to the way that the
image is displayed on the screen.

Obviously, in order to know what pixel any coordinate refers
to, we need to know which coordinate system we are using.  The
coordinate (5, 10) means `img[5, 10]` if it's in array
coordinates, and `img[10, 5]` if it's in imaging coordinates.

## Row and columns

For a 2D image, there appears to be no ambiguity in the term
"row" or "column".  Both the "ij" and "xy" convention think of the row of an image as going left to right in the display, and therefore, in terms of the image array, the row at position 5 is given by:

```{python}
# Row at position 5.
row_5 = img[5, :]
```

Columns in both conventions run top to bottom, so the column at position 10 is given by:

```{python}
# Column at position 10.
col_10 = img[:, 10]
```

Thus, for a *2D grayscale array*, we can talk about *row, column* coordinates ("rc" coordinates), where the first axis gives row position, and the second axis give column position.  Of course, *for the 2D case* this is the same as the "ij" convention.

There are various instances in Scikit-image, of coordinate values referring to row and column axes.  `skimage.draw` has many such instances.  Here's the docstring for `skimage.draw.line`:

```python
def line(r0, c0, r1, c1):
    """Generate line pixel coordinates.

    Parameters
    ----------
    r0, c0 : int
        Starting position (row, column).
    r1, c1 : int
        End position (row, column).

    Returns
    -------
    rr, cc : (N,) ndarray of int
        Indices of pixels that belong to the line.
        May be used to directly index into an array, e.g.
        ``img[rr, cc] = 1``.

    ...
    """
```

## Rows and columns in 3D

We've emphasized that the "rc" convention is the same as the "ij" convention for 2D.

Now consider an image with more than two dimensions.

```{python}
img_4d = ski.data.cells3d()
img_4d.shape
```

In fact the first dimension tracks over a third spatial dimension, the second tracks two different things being imaged in the same sample — `img_4d[:, 0]` gives cell membranes, `img[:, 1]` gives cell nuclei.  The third and fourth dimensions are the rows and columns of the 2D images.

Let's first select out the nuclei, to give a 3D image of nuclei:

```{python}
# Select images of nuclei
img_3d = img_4d[:, 1]
img_3d.shape
```

We're going to allow ourselves to sink into confusion for a few paragraphs, so hold on tight.

The first axis is the third spatial axis of the image.   We
might call this axis — the "plane" axis.  We can think of
`img_3d` as containing a series of 2D images stacked on top of
each other, where the first axis selects the plane, the second
the "row" of the image, and third the "column" of the image.

For example, to show the middle plane:

```{python}
middle_i = img_3d.shape[0] // 2
img_2d = img_3d[middle_i, :, :]
plt.imshow(img_2d)
```

Where's the confusion?  Well — for a 2D image, we were happy
to call the first array axis the "row" axis.  It's the row
axis, because that axis represents rows in the displayed
image.  For a 2D image, this is also the "i" axis, because
it's the first axis.

However, now we're in 3D, the first axis is no longer the
"row" axis, because the row axis is the axis representing the
rows in a 2D image.  So we now find ourselves wanting to call
the second axis (of `img_3d`) the "row" axis, if we are
thinking in terms of displayed 2D images.  The "row" axis is
no longer the same as the "i" axis — if anything it is the "j"
axis, where the "column" axis is the "k" axis.

This is to point out that "row" carries a meaning in terms of how we think of
the array, for 2D display.  In our example, the "row" axis might be the second
axis, but then again, it depends how you think of the 3D image in terms of 2D.
We could also think of `img_3d` as a stack of 2D images, where displayed rows
and columns are the first two dimensions, and the third is the last spatial
dimension:

```{python}
middle_k = img_3d.shape[2] // 2
another_img_2d = img_3d[:, :, middle_k]
plt.imshow(another_img_2d)
```

So, "row" becomes ambiguous here — the axis we think of as
corresponding to rows, depends on how we think of the image
display.  That is, "row" is a *semantic* label for an axis,
telling us what that axis means.

In contrast, when we use "i", or "j" or "k" to label an axis,
we intend no semantic meaning — we just refer to the first,
second and third axis of an array, regardless of the meaning
of these axes.

## m and n are ambiguous labels

In various places in Skimage1, we refer to axes as `M` or `N`.  For example,
see the docstring listed in full further below for the `rank.equalize` filter:

```rest
    def equalize(image, footprint, out=None, mask=None, shift_x=0, shift_y=0, shift_z=0):
        ...
        image : ndarray of shape ([P,] M, N) and dtype (uint8 or uint16)
            Input image.
```

Here `M` and `N` appear to mean (semantic) "row" and "column", because `P`
should usually be taken to mean the plane axis.  However, elsewhere — for
example in the `watershed` function whose docstring we list further below — we
have:

```rest
    image : (M, N[, ...]) ndarray
        Data array where the lowest value points are labeled first.
```

where `M`, `N` appear to mean `i`, `j`.   Given the ambiguity, we suggest
dropping `M` and `N` as axis labels, in favor of `i` and `j`.

## Semantic and not-semantic labels

We will therefore call "row" and "column" and "plane"
*semantic* axis labels, because each tells about what that
particular axis means in terms of image display.

"i", "j" and "k" are non-semantic axis labels, and only refer
to the first second and third axes of the array.

## Convention and semantic labels

In general, in code, when we use "row" or "column" or "plane"
as axis labels, we would like to be able to predict which axes
these refer to, in terms of the image.  The only way we can do
that, short of having an array structure where we can
explicitly label the axes (such as
[xarray](https://docs.xarray.dev), is *by convention*.  That
is, we always make sure that, for example, the "plane" axis is
first, the "row" axis is second, and the "column" axis is
third.

Conventions can differ in different fields.  For example, in
my own (MB) field of brain imaging, the convention is for 3D
brain images to be row first, then columns, then plane, so
"plane", by convention, is the last axis, not the first.

In fact, you can already see conventions for axis positions in
play with 2D color images.  Typically, we represent 2D color
images with the three or four color channels running along the
third axis. That is a typical (by convention) 2D color image
is 3D, with rows as the first dimension, columns as the
second, and color channel as the third.

## Skimage and row, column

I am going to argue that "row" and "column" should always be treated as
semantic labels, in that they refer to the displayed rows and columns of the
image, and the way you display an image is your choice, according to the
meaning of the axes.

But — there may be situations where the semantic meaning,  in practice, always corresponds to axes.  I would argue that the criterion should be:

> a) Does "row" always mean the first axis, in practice?
> b) Does "column" always mean the second axis, in practice?

If so, the use of "row" and "column" *may be* acceptable, and is a synonym for
"i" and "j" in the "i, j" convention.

Otherwise "row" and "column" are generally not acceptable, and need to be
rephrased in terms of "i, j, k ...".

Cursor (the AI agent) identified multiple instances of row and column
references in docstrings and variables.

## Skimage and planes

Like "row" and "column", "plane" is a semantic label.  I am going to argue
that "plane" should not be used, as it is up the particular field or library,
which axis corresponds to the meaning "plane".   We should replace use of
"plane" in the library with "i, j, k" — i.e. use Numpy axis labels to make the
intention clear.   We should instead specify the plane axis, where necessary,
with a `plane_axis=` keyword argument.

## Policy

* We will prefer axis-order labels (I, J, ...) whenever possible.
* Any reference to "row" and "column" in docstrings or variable names, that can
  also be strictly interpreted as axis orders, should change to I, J... or i,
  j ...
* When we need the user to think about semantic meanings of axes, we should:
  * Explain that this is the case (and that this is not the default case),
  * Try to move any semantic labeling to keyword arguments, of form
    `channel_axis=` and `plane_axis=`.
  * Where this fails, make it clear in documentation that this is a special case.

### Use of plane in the codebase

* `src/skimage/measure/_ccomp.pyx:    # Handle first plane`.  This is in
  `scan3D`, called from `label_cython` in the same file.  Here the input array
  `input_` is first axis-reordered to order axes in ascending size, before
  calling `scan3D`, and the array is then axis-reordered to match input.
  `label_cython` gets called (named `clabel`) in `_label.py` `label` function.
  This implies that we can roll axes and run algorithm, then roll back to get
  the same result.  Tested, provisionally confirmed in `label_example.ipynb`
  — labels show 1 to 1 mapping when running label on rolled versions of binary
  image.
* `src/skimage/draw/draw.py`: `rectangle`.  `start` input argument is:

  ```rest
    start : tuple
        Origin point of the rectangle, e.g., ``([plane,] row, column)``.
    end : tuple
        End point of the rectangle ``([plane,] row, column)``.
        For a 2D matrix, the slice defined by the rectangle is
        ``[start:(end+1)]``.
        Either `end` or `extent` must be specified.
    extent : tuple
        The extent (size) of the drawn rectangle.  E.g.,
        ``([num_planes,] num_rows, num_cols)``.
        Either `end` or `extent` must be specified.
        A negative extent is valid, and will result in a rectangle
        going along the opposite direction. If extent is negative, the
        `start` point is not included.
  ```

  This does assume a semantic meaning to the first dimension, and to the second
  and third, which are "row" and "column".  But it doesn't appear a semantic
  meaning is needed.  One option is to change docstring to:

  ```
    start : tuple
        Origin point of the rectangle, e.g., ``(i, j, [k])``.
    end : tuple
        End point of the rectangle ``([i, j, [k])``.
        For a 2D matrix, the slice defined by the rectangle is
        ``[start:(end+1)]``.
        Either `end` or `extent` must be specified.
    extent : tuple
        The extent (size) of the drawn rectangle.  E.g.,
        ``(n_i, n_j[, n_k])``.
        Either `end` or `extent` must be specified.
        A negative extent is valid, and will result in a rectangle
        going along the opposite direction. If extent is negative, the
        `start` point is not included.
  ```

* Various `filter.rank` functions calling `_core_3D` in
  `filters/rank/core_cy_3d.pyx`.  Maybe all in `rank.generic`, e.g
  `rank.equalize`, called with these inputs:

  ```rest
    def equalize(image, footprint, out=None, mask=None, shift_x=0, shift_y=0, shift_z=0):
        """Equalize image using local histogram.

        Parameters
        ----------
        image : ndarray of shape ([P,] M, N) and dtype (uint8 or uint16)
            Input image.
        footprint : ndarray
            The neighborhood expressed as an ndarray of 1's and 0's.
        out : ndarray of shape ([P,] M, N), same dtype as input `image`
            If None, a new array is allocated.
        mask : ndarray of dtype (int or float), optional
            Mask array that defines (>0) area of the image included in the local
            neighborhood. If None, the complete image is used (default).
        shift_x, shift_y, shift_z : int
            Offset added to the footprint center point. Shift is bounded to the
            footprint sizes (center must be inside the given footprint).

        Returns
        -------
        out : ([P,] M, N) ndarray, same dtype as `image`
            Output image.
  ```

  Input image can be 3D, and arguments `shift_x`, `shift_y`, and `shift_z`. But
  the `shift_` arguments appear, oddly, to be offsets in `i, j, k` respectively
  of the `footprint`.   There are specific 3D implementations in the
  `generic.py` filters, called as `generic_cy._<name>_3D`. For example, in
  `equalize`, this is `generic_cy._equalize_3D`.  These functions are
  implemented in `generic_cy.pyx`, and each end up calling the `_core_3D`
  function in `filters/rank/core_cy_3d.pyx`.  `plane` is used in Cython
  function `_core_3D` and functions called therefrom.  So the question is
  — does `_core_3D` treat the first dimension as special in some way?
  Testing suggests no — all filters with `shift_z` (allowing 3D) give the same
  result applied directly, or applied after transposing axes in all
  permutations, applying the filter, and retransposing.   Action: change
  docstrings accordingly to `(i, j[, k])` rather than `([P,] M, N)`.

  We have a problem for the `shift_` parameters.  Their meanings are different for 2D compared to 3D.  For 2D, `shift_x` means `shift_j`, `shift_y` means `shift_i`.  For 3D, `shift_x,y,z` mean `shift_i,j,k`.  So `x` and `y` mean different things for the 3D case.

  We should deprecate `shift_{x,y,z}`, in favor of a generic `shifts` argument, where the elements are in `i, j[, k]` order, and make
  this keyword only.   The question is what message to give those using Skimage1, for porting to Skimage2.

  To note, Github searches suggest it is very rare to use not-default values for any of the `shift_{x,y,z}` parameters.

  Here are the searches for keyword use, split into two because the full `|` search for all rank filter names returned too many results:

  ```
  /(autolevel|equalize|gradient|majority|maximum|mean|geometric_mean|subtract_mean|pop)\(.*?,.*?,.*shift_[xyz]\s*=/ AND NOT path:skimage AND (path:.py OR path:.ipynb)
  ```

  (Only [shift_z=1](https://github.com/NeuroDataDesign/mouselit/blob/dd11ee4a600f378c760cfb072027e331e00d70f2/ryan/3D%20Equalizer/Proof%20of%203D%20Equalization.ipynb#L240))

  and

  ```
  /(threshold|noise_filter|entropy|otsu|sum|median|minimum|modal|enhance_contrast)\(.*?,.*?,.*shift_[xyz]\s*=/ AND NOT path:skimage AND (path:.py OR path:.ipynb)
  ```

  (One non-default use of `shift_x`
  [here](https://github.com/geojames/CNN-Supervised-Classification/blob/594326487372ff06e45aa8a06913fdd9b2aa90fe/code/CnnSupervisedClassification.py#L402);
  [shift to upper left corner with x and
  y](https://github.com/giuliapusc/guessTheSketch/blob/9a3f1a1387d0beb4a254da9c4b58166a1398255b/analysis/entropy_analysis.py#L25)

  (Positional argument search rather harder, but I'll assume these are no more
  common than by keyword).

  Plan: in Skimage2, make everything after `image, footprint` keyword only.
  Remove `shift_{x,y,z}` arguments.  Add `shifts` argument with default None.
  Shifts should be of same number of dimensions of `image` if specified, and
  contain footprint shifts in `i, j, k` order.

  Skimage1 wraps Skimage2 routine, and unpacks `shift_{x,y,z}` into `shifts`
  accordingly.  Deprecation message on lines of (e.g. for `equalize`):

  ```rest
  For Skimage2 ``filters.rank.equalize``, all parameters after `footprint` are
  keyword only.  In Skimage2, specify footprint shifts with `shifts` keyword
  argument.  Specify shifts in `i, j[, k]` order.  Note that, for 2D images,
  `shift_x` in Skimage1 corresponds to `j` (the second axis of the footprint)
  and `shift_y` corresponds to `i` (first axis of footprint). Thus a call with
  `shift_x=1, shift_y=2` for Skimage1 should become `shifts=(2, 1)` in
  Skimage2, and a call with `shift_y=2` (and no `shift_x`) would be
  `shifts=(2, 0)` in Skimage2.  For 3D images, in Skimage1, `shift_x`,
  `shift_y`, and `shift_z` correspond to `i, j, k` (the first, second and
  third axes of the footprint).  Thus a call with `shift_x=1, shift_y=2,
  shift_z=3` in Skimage 1 would use `shifts=(1, 2, 3)` in Skimage2. A call
  with `shift_y=2` (and no specification for `shift_x` or `shift_z`)
  corresponds, in Skimage2, to `shifts=(0, 2, 0)`.
  ```

* `src/skimage/restoration/deconvolution.py` :

  ```rest
  def richardson_lucy(image, psf, num_iter=50, clip=True, filter_epsilon=None):
      """Richardson-Lucy deconvolution.

      Parameters
      ----------
      image : ([P, ]M, N) ndarray
         Input degraded image (can be n-dimensional). If you keep the
         default `clip=True` parameter, you may want to normalize
         the image so that its values fall in the [-1, 1] interval to avoid
         information loss.
      ...
  ```

  This ends up calling `scipy.signal.convolve` on the input array, so no
  semantic meaning to the axes, and docstring better put as:

  Plan:

  ```rest
      Parameters
      ----------
      image : N-D ndarray
  ```

* `segmentation/_watershed.py` `watershed` function:

  ```rest
  def watershed(
      image,
      markers=None,
      connectivity=1,
      offset=None,
      mask=None,
      compactness=0,
      watershed_line=False,
  ):
    """Find watershed basins in an image flooded from given markers.

    Parameters
    ----------
    image : (M, N[, ...]) ndarray
        Data array where the lowest value points are labeled first.
    markers : int, or (M, N[, ...]) ndarray of int, optional
        The desired number of basins, or an array marking the basins with the
        values to be assigned in the label matrix. Zero means not a marker. If
        None, the (default) markers are determined as the local minima of
        `image`. Specifically, the computation is equivalent to applying
        :func:`skimage.morphology.local_minima` onto `image`, followed by
        :func:`skimage.measure.label` onto the result (with the same given
        `connectivity`). Generally speaking, users are encouraged to pass
        markers explicitly.
    connectivity : int or ndarray, optional
        The neighborhood connectivity. An integer is interpreted as in
        ``scipy.ndimage.generate_binary_structure``, as the maximum number
        of orthogonal steps to reach a neighbor. An array is directly
        interpreted as a footprint (structuring element). Default value is 1.
        In 2D, 1 gives a 4-neighborhood while 2 gives an 8-neighborhood.
    offset : array_like of shape image.ndim, optional
        The coordinates of the center of the footprint.
    mask : (M, N[, ...]) ndarray of bools or 0's and 1's, optional
        Array of same shape as `image`. Only points at which mask == True
        will be labeled.
    compactness : float, optional
        Use compact watershed [1]_ with given compactness parameter.
        Higher values result in more regularly-shaped watershed basins.
    watershed_line : bool, optional
        If True, a one-pixel wide line separates the regions
        obtained by the watershed algorithm. The line has the label 0.
        Note that the method used for adding this line expects that
        marker regions are not adjacent; the watershed line may not catch
        borders between adjacent marker regions.

    Returns
    -------
    out : ndarray
        A labeled matrix of the same type and shape as `markers`.
  ```

  This looks like a generic N-D function.  However, tests in
  `watershed_3d_axes.Rmd` show that running on a transposed image, and
  re-transposing, does not give equivalent labels.

  **Check**.  Provisional plan: change `(M, N[, ...])` to `(i, j[, ...])`.

Other instances (via `ripgrep`) of `plane` to review in code-base:

```
src/skimage/graph/spath.py:    # Valid starting positions are anywhere on the hyperplane defined by
src/skimage/graph/spath.py:    # hyperplane at position -1 along the same.
src/skimage/graph/_mcp.pyx:    """Return an array with edge points/lines/planes/hyperplanes marked.
src/skimage/segmentation/_slic.pyx:    a cut-plane through the volume. So, if the order was (x, y, z) and
src/skimage/segmentation/_slic.pyx:    we wanted to look at the 5th cut plane, we would write::
src/skimage/segmentation/_slic.pyx:        my_z_plane = img3d[:, :, 5]
src/skimage/segmentation/_slic.pyx:        my_z_plane = img3d[5]
src/skimage/restoration/_denoise.py:    plane separately.
src/skimage/restoration/_nl_means_denoising.pyx:    # Iterate over planes, taking padding into account
src/skimage/restoration/_nl_means_denoising.pyx:        Shift along the plane axis.
src/skimage/restoration/_nl_means_denoising.pyx:        Shift along the plane axis.
src/skimage/restoration/_nl_means_denoising.pyx:        # Iterate over shifts along the plane axis
src/skimage/restoration/_nl_means_denoising.pyx:                    # Iterate over planes, taking offset and shift into account
src/skimage/restoration/_nl_means_denoising.pyx:    # Iterate over shifts along the plane axis
src/skimage/restoration/_nl_means_denoising.pyx:                        # Iterate over planes, taking offset and shift into account
```

Also see output of `rg "\(M\s*,\s*N"` on codebase in `mn.md`.  There are
multiple instances of `M, N[, P]` etc.

## x and y in variables and docstrings

We have various instances of "x" and "y" in signatures, docstrings and code.

Most of the time, "x" means "column" or "j", and "y" means "row" or "i".

In those cases, we should have the following policy:

* Deprecate use of "x" and "y" (when they have meaning "column" and "row"),
  and prefer "i" and "j" (or maybe "column" and "row").  We should also either
  make these keyword-only, or change the default parameter order to prefer
  "i", "j" order rather than "column", "row" order.
* We may want to either:

  a) add an extra keyword argument similar to `coord_convention='xy' | 'ij'` or
  b) recommend `skimage2` version of same function, that uses "ij" by default.

  For compatibility, we will need either the keyword argument (as above) or some helper to explain how to achieve the "x, y" effect using the Skimage2 "i, j" implementation.

### Examples of "x", "y"

* `predict_x`, `predict_y`, `predict_xy` in transform classes.  The transform
  classes use "x" to mean the first column in an n by 2 coordinate array, and
  "y" to mean the second.  And by convention, they are written as if they
  expect the "x" coordinate to be image column coordinates, and "y" to be
  image row coordinates.  However, there is no reason in the code that the
  first column could not be image row coordinates, and the second be image
  column coordinates.  So `predict_x` in fact means, predict coordinate in
  first coordinate column, and so on.  We can therefore rephrase these as `predict_i`, `predict_j`, and `predict_ij`.

* `skimage.feature.corner.structure_tensor` and `hessian_matrix` have an
  `order='rc' | 'xy'` input parameter that default to "rc" (meaning "ij").  Here's the parameter description from the docstring:

  ```rest
    order : {'rc', 'xy'}, optional
        NOTE: 'xy' is only an option for 2D images, higher dimensions must
        always use 'rc' order. This parameter allows for the use of reverse or
        forward order of the image axes in gradient computation. 'rc' indicates
        the use of the first axis initially (Arr, Arc, Acc), whilst 'xy'
        indicates the usage of the last axis initially (Axx, Axy, Ayy).
  ```

  There are currently 6 uses of this `'xy'` option on Github with search
  `/structure_tensor\(.*,.*["']xy["']/  AND NOT path:test_corner.py`
  (to avoid copies of the Skimage test suite).  Five are within `nematic` and
  `NematicTL` repos by `viciya`; one is in a project repo
  `tiagopetena/computer_vision`.  These could be resolved by suitable PRs.  But `/hessian_matrix\(.*,.*["']xy["']/  AND NOT path:test_corner.py` occurs in 41 files, so that would be some work to resolve with PRs.  In neither case is the `order='xy'` case easy to pull out with a helper function.

  Suggest retaining this option in Skimage2, leaving with default `rc`
  behavior.  Perhaps we could deprecate at some later stage.


## Documentation

Edit:

> CONTRIBUTING.rst:* Refer to array dimensions as (plane), row, column, not as
x, y, z. See :ref:`Coordinate conventions
<numpy-images-coordinate-conventions>` in the user guide for more information.

And edit that document (`doc/source/user_guide/numpy_images.rst`) for plane
conventions etc.
